"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var llama_exports = {};
__export(llama_exports, {
  GENERIC_MODEL: () => GENERIC_MODEL,
  KNOWN_MODELS: () => KNOWN_MODELS,
  LlamaConfigSchema: () => LlamaConfigSchema,
  defineModel: () => defineModel,
  isLlamaModelName: () => isLlamaModelName,
  listActions: () => listActions,
  listKnownModels: () => listKnownModels,
  model: () => model
});
module.exports = __toCommonJS(llama_exports);
var import_genkit = require("genkit");
var import_model = require("genkit/model");
var import_openai = __toESM(require("openai"));
var import_common = require("../../common/index.js");
var import_openai_compatibility = require("./openai_compatibility.js");
var import_utils = require("./utils.js");
const LlamaConfigSchema = import_openai_compatibility.OpenAIConfigSchema.extend({
  location: import_genkit.z.string().optional()
}).passthrough();
function commonRef(name, info, configSchema = LlamaConfigSchema) {
  return (0, import_model.modelRef)({
    name: `vertex-model-garden/${name}`,
    configSchema,
    info: info ?? {
      supports: {
        multiturn: true,
        tools: true,
        media: true,
        systemRole: true,
        output: ["text", "json"]
      }
    }
  });
}
const GENERIC_MODEL = commonRef("llama");
const KNOWN_MODELS = {
  "meta/llama-4-maverick-17b-128e-instruct-maas": commonRef(
    "meta/llama-4-maverick-17b-128e-instruct-maas"
  ),
  "meta/llama-4-scout-17b-16e-instruct-maas": commonRef(
    "meta/llama-4-scout-17b-16e-instruct-maas"
  ),
  "meta/llama-3.3-70b-instruct-maas": commonRef(
    "meta/llama-3.3-70b-instruct-maas"
  ),
  "meta/llama-3.2-90b-vision-instruct-maas": commonRef(
    "meta/llama-3.2-90b-vision-instruct-maas"
  ),
  "meta/llama-3.1-405b-instruct-maas": commonRef(
    "meta/llama-3.1-405b-instruct-maas"
  ),
  "meta/llama-3.1-70b-instruct-maas": commonRef(
    "meta/llama-3.1-70b-instruct-maas"
  ),
  "meta/llama-3.1-8b-instruct-maas": commonRef(
    "meta/llama-3.1-8b-instruct-maas"
  )
};
function isLlamaModelName(value) {
  return !!value?.startsWith("meta/llama-");
}
function model(version, options = {}) {
  const name = (0, import_utils.checkModelName)(version);
  return (0, import_model.modelRef)({
    name: `vertex-model-garden/${name}`,
    config: options,
    configSchema: LlamaConfigSchema,
    info: {
      ...GENERIC_MODEL.info
    }
  });
}
function listActions(clientOptions) {
  return [];
}
function listKnownModels(clientOptions, pluginOptions) {
  return Object.keys(KNOWN_MODELS).map(
    (name) => defineModel(name, clientOptions, pluginOptions)
  );
}
function defineModel(name, clientOptions, pluginOptions) {
  const ref = model(name);
  const clientFactory = async (request) => {
    const options = await resolveOptions(clientOptions, request.config);
    return new import_openai.default(options);
  };
  return (0, import_openai_compatibility.defineOpenaiCompatibleModel)(ref, clientFactory);
}
async function resolveOptions(clientOptions, requestConfig) {
  const baseUrlTemplate = clientOptions.baseUrlTemplate ?? "https://{location}-aiplatform.googleapis.com/v1/projects/{projectId}/locations/{location}/endpoints/openapi";
  const location = requestConfig?.location || clientOptions.location;
  const baseURL = baseUrlTemplate.replace(/{location}/g, location).replace(/{projectId}/g, clientOptions.projectId);
  const apiKey = await clientOptions.authClient.getAccessToken();
  if (!apiKey) {
    throw new import_genkit.GenkitError({
      status: "PERMISSION_DENIED",
      message: "Unable to get accessToken"
    });
  }
  const defaultHeaders = {
    "X-Goog-Api-Client": (0, import_common.getGenkitClientHeader)()
  };
  return { baseURL, apiKey, defaultHeaders };
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  GENERIC_MODEL,
  KNOWN_MODELS,
  LlamaConfigSchema,
  defineModel,
  isLlamaModelName,
  listActions,
  listKnownModels,
  model
});
//# sourceMappingURL=llama.js.map